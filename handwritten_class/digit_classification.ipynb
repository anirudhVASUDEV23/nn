{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "396157b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48947231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f55da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),## 0->255 to 0->1\n",
    "    transforms.Normalize((0.5),(0.5))##using normalize 0->1 to -1 to +1 when data is 0 centered nn will learn better mean,std as arguements normalized pixel=pixel-mean/std\n",
    "])\n",
    "\n",
    "train_dataset=datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset=datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6084309c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84010277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af835db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66aeadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter=iter(train_loader)\n",
    "images,labels=next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2fe1844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54b610ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53d5defe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f146077d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x200106b0c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].squeeze(),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c88d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914571d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Flatten(),##28*28 into array of 784 pixels\n",
    "            nn.Linear(784,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a248447",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DigitsClassifier()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)##like gd only but its optimized\n",
    "criterion=nn.CrossEntropyLoss()##multi class classification criterion is a function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a00944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.39347178722495463\n",
      "Epoch 2 loss: 0.184409593390837\n",
      "Epoch 3 loss: 0.13247496748406654\n",
      "Epoch 4 loss: 0.10829104978873182\n",
      "Epoch 5 loss: 0.09484550174174787\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss=0.0\n",
    "    for images,labels in train_loader:\n",
    "        #1.Forward pass\n",
    "        outputs=model(images)##outputs is like \n",
    "        loss=criterion(outputs,labels)\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "\n",
    "        #2.Backward pass\n",
    "        optimizer.zero_grad()##making previous gradients 0 \n",
    "        loss.backward()\n",
    "\n",
    "        #3.weight update\n",
    "        optimizer.step() #w_old=w_new-learning_rate*gradient\n",
    "\n",
    "    print(f\"Epoch {epoch+1} loss: {running_loss/len(train_loader)}\") \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Yes, exactly! üëç\n",
    "\n",
    "# For outputs in the context of your for images, labels in train_loader: loop, it is a 2D PyTorch tensor. Each row of this 2D tensor is a 1D array (or vector) of size 10, representing the model's predicted logits for one image in the batch.\n",
    "\n",
    "# So, if your batch_size is 64, the outputs tensor will have a shape of [64, 10].\n",
    "\n",
    "# The first dimension (64) corresponds to the number of images in the current batch.\n",
    "\n",
    "# The second dimension (10) corresponds to the 10 output logits (unnormalized scores) for each of the 10 possible classes (digits 0-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d361d03",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5baf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2775e+01, -5.7256e+00, -2.8206e-01, -7.0219e+00, -6.0243e+00,\n",
      "         -5.8277e+00,  2.4789e+00, -7.2803e+00, -5.1882e+00, -2.5150e+00],\n",
      "        [-1.4346e+00,  9.6965e+00, -3.6848e+00, -3.9955e+00, -1.4957e+00,\n",
      "         -7.1997e+00, -4.3065e+00, -3.4331e+00,  5.8829e-01, -8.1213e+00],\n",
      "        [-2.3652e+00, -3.1458e+00, -1.4958e+00,  7.1528e+00, -7.5926e+00,\n",
      "          1.7474e+00, -1.1907e+01, -6.7203e-01, -3.6750e-01,  2.9547e+00],\n",
      "        [-3.0401e+00, -9.5181e-01, -5.8707e-01, -1.2124e+00, -8.3529e+00,\n",
      "          1.7998e+00, -1.2072e+01,  8.4686e+00, -2.8273e+00, -3.6946e+00],\n",
      "        [-5.0683e+00,  1.7557e+00, -5.4911e+00, -5.2017e+00,  1.3459e+01,\n",
      "         -6.7945e+00, -3.1089e+00,  1.2889e+00, -3.2040e+00,  3.0224e+00],\n",
      "        [-8.3285e+00, -5.8989e+00,  9.0695e+00, -5.5531e-02, -5.4915e+00,\n",
      "         -3.1209e+00, -9.0694e+00, -1.5647e+00, -1.6563e-01, -7.8836e+00],\n",
      "        [-4.0753e+00,  1.8188e+00,  4.5745e-01, -4.2410e-01, -5.5717e+00,\n",
      "         -5.0990e+00, -1.5184e+01,  9.3348e+00, -2.7588e+00, -1.1339e+00],\n",
      "        [-3.0133e+00, -4.6303e-01, -1.5308e+00,  4.9865e-01,  2.9934e+00,\n",
      "         -3.2910e+00, -1.0427e+01,  4.3501e-01, -3.1116e+00, -1.9039e-01],\n",
      "        [-5.3044e+00,  6.1928e+00, -2.6132e+00,  1.5542e+00, -1.4637e+00,\n",
      "         -2.9563e+00, -1.8381e+00, -1.7145e+00, -2.8842e-01, -1.8641e+00],\n",
      "        [ 1.8064e+00,  1.5179e+00, -4.5714e+00, -1.2672e+00, -9.1645e+00,\n",
      "          5.3575e+00, -2.6843e+00, -1.0412e+00, -1.5092e+00, -7.5920e+00],\n",
      "        [ 4.9531e+00, -4.0942e+00, -9.4336e-01, -7.6188e+00,  1.1129e+00,\n",
      "         -3.1823e+00,  6.4771e+00, -7.3860e+00, -4.9219e+00, -3.5930e+00],\n",
      "        [ 1.6239e-01, -5.0845e+00, -3.1638e+00, -8.3248e+00,  5.6336e+00,\n",
      "         -1.1757e+00,  1.2172e+01, -7.2829e+00, -5.0617e+00, -5.9931e+00],\n",
      "        [-3.5170e+00, -6.7520e+00,  8.5153e-01, -9.3481e-01, -4.7113e+00,\n",
      "         -9.9151e-01,  7.0527e-01, -1.2002e+01,  1.1464e+01, -4.3608e+00],\n",
      "        [ 1.8032e+00, -3.9417e+00, -4.2037e+00, -4.9412e+00,  1.9151e+00,\n",
      "          1.4169e+00,  7.4672e+00, -4.5342e+00, -2.0749e+00, -5.4927e+00],\n",
      "        [-1.0044e+01,  2.0648e+00,  9.8838e+00,  6.2323e+00, -1.2600e+01,\n",
      "         -8.5021e+00, -1.1556e+01, -2.8282e+00,  4.4926e+00, -1.5225e+01],\n",
      "        [ 5.1691e+00, -8.8955e+00,  5.7182e-01, -6.4527e+00,  1.4016e+00,\n",
      "         -4.8073e+00,  8.2899e+00, -4.5826e+00, -1.5303e+00, -3.8221e+00],\n",
      "        [ 4.2054e-01, -5.0195e+00, -6.6448e+00, -4.7001e+00, -8.1201e+00,\n",
      "          1.1298e+01, -2.7574e+00, -1.7668e+00, -2.0135e+00, -3.6324e+00],\n",
      "        [-8.9191e+00, -7.2847e-01, -2.4033e+00,  4.7034e+00, -7.4129e+00,\n",
      "          8.3415e+00, -4.5154e+00, -1.0884e+01,  4.5887e-01, -3.4279e+00],\n",
      "        [-3.3621e+00, -7.8734e+00, -4.3120e+00, -6.4588e+00,  1.1557e+01,\n",
      "         -3.6614e+00, -3.8869e+00,  3.7223e-01, -1.1312e+00,  2.6187e+00],\n",
      "        [-3.9325e+00,  8.0020e+00, -4.1436e+00, -2.8521e+00, -1.1144e-01,\n",
      "         -4.7924e+00,  1.7754e+00, -4.0197e+00,  2.3698e+00, -4.9409e+00],\n",
      "        [-5.5862e+00, -5.0460e-01, -7.9960e+00, -3.4698e+00,  1.2330e+01,\n",
      "         -2.5926e+00, -6.8995e+00, -1.0682e+00, -7.6914e-01,  5.5599e+00],\n",
      "        [-2.0120e+00, -3.9317e+00,  1.7413e-01, -5.3722e+00,  2.4409e+00,\n",
      "          2.1817e+00,  1.2622e+01, -8.5858e+00, -2.3418e+00, -8.7503e+00],\n",
      "        [-3.8615e+00, -4.4606e+00, -3.6901e+00, -1.8836e+00,  8.6342e+00,\n",
      "         -5.6998e+00, -4.0063e+00,  1.0693e-01, -2.6337e+00,  4.3543e+00],\n",
      "        [-1.5002e+00, -6.3925e+00, -2.3575e+00, -1.8238e+00,  7.9748e+00,\n",
      "         -6.8135e-01, -3.4960e+00, -2.3423e+00, -3.1913e+00,  9.8345e-01],\n",
      "        [ 2.4381e+00, -2.5746e+00, -1.7277e-01,  1.1020e+00, -4.0689e+00,\n",
      "         -1.0200e+00,  4.4824e+00, -5.6715e+00, -1.7277e+00, -9.1383e+00],\n",
      "        [ 1.3335e+00, -1.8255e+00, -5.5610e+00, -5.7669e-01, -7.3507e+00,\n",
      "          6.3774e+00, -5.3880e-01, -5.2030e+00, -1.4076e+00, -7.5266e+00],\n",
      "        [-3.9695e+00, -6.8796e+00, -4.0879e+00,  4.3740e-01,  2.0990e-01,\n",
      "          1.9035e+00, -7.8213e+00, -1.0784e+00,  1.5713e+00,  7.8813e+00],\n",
      "        [-3.9325e+00, -3.1631e+00, -4.6413e+00, -2.7881e+00,  9.2760e+00,\n",
      "         -7.9516e+00, -4.6413e+00,  3.8725e+00, -2.5998e+00,  3.8920e+00],\n",
      "        [-1.0791e+01, -4.0172e-01,  1.0480e+01,  2.3016e+00, -9.5374e+00,\n",
      "         -2.6209e+00, -3.3115e+00, -1.9556e+00, -1.5086e+00, -1.4557e+01],\n",
      "        [-3.1868e+00, -1.6828e+00, -3.5487e+00, -5.1609e+00,  8.0651e-02,\n",
      "         -6.0188e+00, -9.6749e+00,  8.3533e+00, -2.2540e+00,  5.0321e+00],\n",
      "        [ 2.3236e+00, -3.3697e+00, -4.2236e+00, -7.5341e+00,  1.6436e+01,\n",
      "         -1.1195e+01,  2.6017e+00, -1.4182e+00, -8.6184e+00, -1.9356e+00],\n",
      "        [-1.1738e+01, -2.1263e-01, -3.4154e+00,  1.2388e+01, -5.9212e+00,\n",
      "          1.8891e+00, -1.3815e+01, -9.3697e+00,  2.9679e+00, -1.6781e+00],\n",
      "        [ 2.0897e+00, -6.6423e+00, -3.9529e+00, -3.8483e+00, -7.2413e+00,\n",
      "         -4.6812e-02, -1.3452e+01,  1.1640e+01, -4.8746e+00,  2.1029e+00],\n",
      "        [-4.6292e+00, -9.4854e-01, -1.9706e+00, -4.6710e+00,  8.6880e+00,\n",
      "         -3.8729e+00,  2.0376e+00, -4.3881e-02, -2.0986e+00, -2.7834e-01],\n",
      "        [ 7.9164e+00, -2.8996e+00, -8.5337e-02, -2.2121e+00, -6.6040e+00,\n",
      "         -1.8315e+00, -7.5812e-01, -1.2138e+00, -4.7655e+00, -6.5194e-01],\n",
      "        [-8.8567e+00,  2.6815e-01, -3.5846e+00, -3.4996e+00,  1.1408e+01,\n",
      "         -6.9848e+00, -1.5200e+00,  3.4104e+00, -4.4424e+00, -2.5449e-01],\n",
      "        [-4.6403e+00,  1.8254e+00, -1.1285e+00,  6.8707e+00, -6.2594e+00,\n",
      "          7.9813e-01, -1.5495e+00, -4.8177e+00, -8.7032e-01, -6.4517e+00],\n",
      "        [-4.3135e+00,  4.9156e-02, -1.3384e+00, -3.7201e-01, -2.2839e+00,\n",
      "         -3.7252e+00, -1.4352e+01,  9.2844e+00, -3.5810e+00,  9.2926e-02],\n",
      "        [ 1.3509e+00, -8.6157e+00, -2.3036e+00, -8.5277e+00,  1.1835e+01,\n",
      "         -8.1281e+00, -3.3928e-01,  1.1048e+00, -3.0447e+00,  3.4415e-01],\n",
      "        [-1.3638e+01, -4.8067e-01, -4.7140e+00,  1.3462e+01, -7.4043e+00,\n",
      "          3.3284e+00, -1.8455e+01, -7.9543e+00,  2.7464e+00,  1.1974e+00],\n",
      "        [-9.4643e+00,  2.9456e+00,  9.6397e+00,  3.0921e+00, -8.8985e+00,\n",
      "         -7.4123e+00, -5.7014e+00, -9.3597e+00,  3.4296e+00, -1.7267e+01],\n",
      "        [-1.1042e+01, -7.8713e-01,  8.9056e+00,  1.0675e+00, -5.7255e+00,\n",
      "         -1.1693e+00, -6.8927e+00, -3.5935e-01, -3.9188e+00, -9.0450e+00],\n",
      "        [-7.7035e-01, -4.9610e+00,  9.5931e-01, -3.3936e+00, -1.3444e+00,\n",
      "          1.3562e+00,  1.1272e+01, -1.0635e+01, -5.9043e-01, -1.0331e+01],\n",
      "        [-6.6203e+00,  6.4261e+00, -2.1847e+00,  1.9254e-02, -1.2824e+00,\n",
      "         -3.3804e+00, -5.1460e-01, -2.9657e+00,  2.3975e+00, -1.5058e+00],\n",
      "        [-4.0998e+00,  1.0041e+01, -3.2104e+00, -3.9351e+00, -9.7260e-01,\n",
      "         -4.8528e+00, -3.6894e+00, -7.4798e-01, -8.3584e-01, -7.6765e+00],\n",
      "        [-2.7915e+00,  6.9985e-01, -3.1929e+00, -5.4166e+00,  8.9938e+00,\n",
      "         -5.1953e+00, -1.6852e+00,  3.0042e-01, -2.0986e+00,  1.7422e+00],\n",
      "        [-9.7208e+00, -3.0675e+00, -3.9132e+00,  1.4068e+01, -8.0619e+00,\n",
      "         -1.7225e+00, -1.8671e+01, -2.0767e+00,  5.4658e+00,  3.0311e+00],\n",
      "        [-5.0487e+00, -4.3941e+00,  6.9196e+00,  2.1445e+00, -1.1842e+01,\n",
      "         -5.3515e+00, -1.0242e+01,  3.6135e+00,  1.9681e+00, -5.6427e+00],\n",
      "        [-6.5017e+00, -2.4396e+00,  3.1307e+00,  5.0723e+00, -8.5911e+00,\n",
      "         -7.1530e+00, -1.3870e+01,  9.4818e+00, -4.4804e+00, -1.1975e+00],\n",
      "        [-4.2876e+00, -3.4157e+00, -1.8738e+00,  2.1336e+00, -4.0269e+00,\n",
      "          1.8277e+00, -2.3081e+00, -6.2166e+00,  6.0613e+00, -1.1863e+00],\n",
      "        [-7.6870e+00, -1.5241e+00, -1.2081e+01,  5.3206e+00, -1.3994e+01,\n",
      "          1.9088e+01, -4.2488e+00, -1.6409e+01, -9.2889e-01,  2.1342e+00],\n",
      "        [-1.1472e+00, -2.5271e+00, -1.1876e+00, -4.5443e-01, -1.4736e+00,\n",
      "          9.9988e-01,  6.3849e+00, -5.2182e+00,  4.2062e-04, -4.3181e+00],\n",
      "        [-3.4689e+00, -7.0487e+00,  1.0588e+01, -1.3477e+00, -1.4577e-01,\n",
      "         -3.2679e+00,  2.8040e+00, -5.9557e+00, -8.5179e+00, -1.4999e+01],\n",
      "        [-1.0291e+01,  3.1604e+00,  1.2342e+00,  1.3510e+01, -5.9212e+00,\n",
      "         -3.5485e+00, -1.6070e+01, -1.1538e+00, -2.0471e+00, -4.4976e+00],\n",
      "        [-6.4801e+00, -4.4079e+00,  1.1403e+01,  2.1546e+00, -9.5102e+00,\n",
      "         -2.6633e+00, -7.5957e+00, -3.3526e+00, -3.2260e+00, -1.0086e+01],\n",
      "        [-4.8568e+00,  1.3656e+00,  3.2531e+00,  1.2746e+00, -1.3631e+01,\n",
      "         -6.3709e+00, -1.6791e+01,  1.2896e+01, -4.9858e+00, -9.6194e-01],\n",
      "        [-3.7817e+00, -2.3491e+00, -1.3448e+00, -1.4977e+00, -2.7302e+00,\n",
      "         -1.8528e+00, -1.8658e+00, -9.5596e+00,  1.0394e+01, -2.0660e+00],\n",
      "        [-6.4854e+00, -1.1572e+00, -3.3785e+00, -2.2553e+00, -1.5973e+00,\n",
      "         -1.6274e+00, -4.4757e+00, -6.7200e+00,  1.1398e+01, -2.2363e+00],\n",
      "        [-4.2481e+00,  7.2543e+00, -7.6983e-01, -1.2692e+00, -2.1828e+00,\n",
      "         -3.8215e+00, -4.1049e+00,  6.7791e-01, -2.0406e+00, -7.3260e+00],\n",
      "        [-3.1278e+00, -7.3584e+00, -4.5038e+00, -9.5290e-02,  6.9129e-01,\n",
      "         -1.1584e+00, -9.0878e+00,  1.0433e+00,  8.7872e-01,  9.7987e+00],\n",
      "        [-1.3360e+01,  2.6422e-01, -1.0718e+00,  1.1406e+01, -9.5537e+00,\n",
      "          4.7388e+00, -1.0193e+01, -5.8780e+00, -2.3161e+00, -6.9995e+00],\n",
      "        [ 9.8272e-01, -3.8604e+00,  3.4674e+00,  1.2422e+00, -1.7485e+00,\n",
      "         -3.7560e+00,  3.3392e+00, -5.8728e+00, -2.9649e+00, -8.4434e+00],\n",
      "        [-5.9805e+00, -5.6239e-01, -3.9796e+00,  1.0639e+01, -9.5096e+00,\n",
      "          5.4313e+00, -9.9917e+00, -6.1170e+00, -1.6842e+00,  1.1312e+00],\n",
      "        [-6.5030e+00, -1.3095e+00,  9.6354e+00,  6.2167e-01, -6.6657e+00,\n",
      "         -1.7685e+00, -5.7276e+00,  9.5107e-01, -4.3794e+00, -1.0704e+01]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images,labels in test_loader:\n",
    "        outputs=model(images)\n",
    "        print(outputs)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a756b960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for images,labels in test_loader:\n",
    "        outputs=model(images)\n",
    "        print(outputs.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b922c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.4055, -5.7618, -5.1618, -0.5579,  5.3081, -3.2464, -9.2675,  0.8436,\n",
      "        -1.3821, 11.3503])\n",
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():##index 9 is the predicted digit\n",
    "    for images,labels in test_loader:\n",
    "        outputs=model(images)\n",
    "        print(outputs[0])\n",
    "        print(labels[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb642c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([ 9.0431, 13.4497, 11.7283, 12.3255, 10.6073, 11.0604, 10.3523, 12.4147,\n",
      "        10.5663, 14.7578, 12.2794,  7.4911, 11.2760, 11.8042,  8.2640, 15.6971,\n",
      "         6.9858,  3.3383,  6.2242,  9.2844,  7.5165, 10.0128,  9.6906,  8.0106,\n",
      "         8.1714, 14.0463,  7.8441,  8.3875,  8.7397,  8.1071,  9.5964, 13.2199,\n",
      "        12.0412,  8.6424,  7.3055,  8.4777,  9.1414, 12.9653, 10.1586,  8.2396,\n",
      "         6.9650,  8.8410, 13.6956,  7.5089, 12.2060,  5.7532, 12.5767,  6.5501,\n",
      "         6.4112, 11.7999,  4.3599,  6.5903,  8.7955,  4.2298, 10.5608,  9.5085,\n",
      "         8.8209,  7.3833,  9.0771,  5.8993, 10.1134, 11.9825,  7.3348, 11.3323]),\n",
      "indices=tensor([2, 8, 2, 7, 2, 4, 1, 5, 9, 8, 2, 4, 9, 4, 7, 2, 9, 0, 2, 7, 1, 1, 9, 7,\n",
      "        1, 3, 9, 9, 1, 6, 2, 6, 5, 1, 7, 2, 5, 7, 3, 2, 1, 2, 0, 1, 5, 2, 0, 9,\n",
      "        5, 7, 4, 4, 6, 6, 3, 7, 6, 9, 3, 7, 3, 0, 3, 3]))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():##index 9 is the predicted digit\n",
    "    for images,labels in test_loader:\n",
    "        outputs=model(images)\n",
    "        print(torch.max(outputs,1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589de9c",
   "metadata": {},
   "source": [
    "<!-- ##torch.max(outputs, 1) returns a tuple where the first tensor contains the maximum value of each row in outputs, and the second tensor contains the index of that maximum value for each row.\n",
    "\n",
    "First tensor (values): This will have a shape of [batch_size, 1]. For each image in the batch, it gives you the highest predicted logit.\n",
    "\n",
    "Second tensor (indices): This will also have a shape of [batch_size, 1] (or sometimes just [batch_size]). For each image, it gives you the index (0-9 for MNIST) where the maximum logit was found, which is the model's predicted class. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88fcc369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 8, 9, 9, 6, 6, 0, 6, 4, 9, 5, 6, 4, 6, 3, 4, 6, 2, 2, 2, 8, 5, 6, 8,\n",
      "        4, 5, 9, 0, 2, 9, 4, 8, 2, 8, 3, 8, 8, 8, 2, 1, 0, 1, 2, 9, 4, 8, 6, 9,\n",
      "        7, 8, 6, 5, 8, 0, 7, 3, 9, 1, 9, 5, 7, 1, 9, 8])\n"
     ]
    }
   ],
   "source": [
    "##it gave the values and the index we are interested in is index 1 as it is the predicted digit\n",
    "with torch.no_grad():##index 9 is the predicted digit\n",
    "    for images,labels in test_loader:\n",
    "        outputs=model(images)\n",
    "        _,predicted=torch.max(outputs,1)\n",
    "        print(predicted)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0771d0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 5, 8, 6, 6, 1, 2, 2, 8, 0, 1, 9, 4, 5, 0, 7, 9, 2, 9, 1, 4, 9, 2, 1,\n",
      "        2, 3, 2, 5, 5, 0, 9, 9, 3, 2, 5, 7, 3, 2, 1, 1, 9, 8, 7, 5, 2, 2, 5, 3,\n",
      "        1, 7, 2, 6, 7, 0, 8, 3, 1, 0, 7, 1, 1, 9, 2, 9])\n",
      "tensor([6, 9, 8, 6, 6, 1, 2, 2, 8, 2, 1, 9, 4, 5, 0, 7, 9, 2, 9, 1, 4, 9, 2, 1,\n",
      "        2, 3, 2, 5, 5, 0, 9, 9, 3, 3, 5, 7, 3, 2, 1, 1, 9, 8, 7, 5, 2, 2, 5, 3,\n",
      "        1, 7, 2, 6, 7, 0, 8, 3, 1, 9, 7, 1, 1, 9, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():##index 9 is the predicted digit\n",
    "    for images,labels in test_loader:\n",
    "        outputs=model(images)\n",
    "        _,predicted=torch.max(outputs,1)\n",
    "        print(predicted)\n",
    "        print(labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "643c8838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 8, 2, 4, 7, 8, 9, 8, 5, 1, 8, 8, 3, 6, 8, 7, 2, 0, 2, 5, 1, 4, 3,\n",
      "        3, 6, 5, 5, 8, 3, 3, 6, 6, 4, 8, 7, 0, 8, 9, 4, 4, 5, 0, 8, 4, 6, 4, 0,\n",
      "        3, 4, 9, 9, 7, 6, 1, 2, 4, 0, 2, 7, 3, 0, 3, 5])\n",
      "tensor([2, 3, 8, 2, 4, 7, 8, 9, 8, 5, 1, 8, 8, 5, 6, 8, 7, 2, 0, 2, 5, 1, 6, 3,\n",
      "        3, 6, 5, 5, 8, 3, 3, 6, 6, 4, 8, 7, 0, 8, 9, 4, 4, 5, 0, 8, 4, 6, 4, 0,\n",
      "        3, 2, 9, 9, 7, 6, 1, 2, 4, 0, 2, 7, 3, 0, 3, 5])\n",
      "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():##index 9 is the predicted digit\n",
    "    for images,labels in test_loader:\n",
    "        outputs=model(images)\n",
    "        _,predicted=torch.max(outputs,1)\n",
    "        print(predicted)\n",
    "        print(labels)\n",
    "        print(predicted==labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfdc7c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 9, 5, 9, 0, 8, 0, 2, 6, 9, 1, 4, 7, 0, 4, 7, 9, 9, 1, 9, 9, 3, 4, 7,\n",
      "        4, 7, 2, 1, 2, 4, 2, 1, 4, 8, 6, 7, 6, 2, 1, 7, 6, 9, 4, 0, 7, 3, 0, 3,\n",
      "        0, 3, 3, 1, 7, 0, 1, 4, 1, 9, 3, 1, 6, 1, 6, 2])\n",
      "tensor([3, 9, 5, 9, 0, 8, 0, 2, 6, 9, 1, 4, 7, 0, 4, 7, 9, 9, 1, 9, 9, 3, 4, 7,\n",
      "        4, 7, 2, 1, 2, 4, 2, 1, 4, 8, 6, 7, 5, 2, 1, 7, 6, 9, 4, 0, 7, 3, 0, 3,\n",
      "        0, 3, 3, 1, 7, 0, 1, 4, 1, 9, 3, 1, 6, 7, 6, 2])\n",
      "tensor(62)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():##index 9 is the predicted digit\n",
    "    for images,labels in test_loader:\n",
    "        outputs=model(images)\n",
    "        _,predicted=torch.max(outputs,1)\n",
    "        print(predicted)\n",
    "        print(labels)\n",
    "        print((predicted==labels).sum())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "033e6214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9641\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "correct=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images,labels in test_loader:\n",
    "        outputs=model(images)\n",
    "        _,predicted=torch.max(outputs,1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=(predicted==labels).sum().item() ##to convert 1d tensor to scalar\n",
    "\n",
    "print(f\"Accuracy: {correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31e6a7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9641)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef5300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
